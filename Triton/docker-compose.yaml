version: "3.9"
services:
    base:
        entrypoint: ["/bin/bash", "-c", "trap : TERM INT; sleep infinity & wait"]
        image: rocm/pytorch:rocm6.1_ubuntu22.04_py3.10_pytorch_2.4
        hostname: test
        build:
          context: .
          dockerfile: Dockerfile
        environment:
            - USE_HTTPS=0
            - INSTALL_ROOT=${INSTALL_ROOT}
        ports:
            - "5555:5555"
        volumes:
            # - type: bind
            #   source: models
            #   target: ${INSTALL_ROOT}/models
            # - type: bind
            #   source: include
            #   target: ${INSTALL_ROOT}/include
            # - type: bind
            #   source: lib
            #   target: ${INSTALL_ROOT}/lib
            - type: bind
              source: code
              target: ${INSTALL_ROOT}/code
            - type: bind
              source: scripts
              target: ${INSTALL_ROOT}/scripts
            # - type: bind
            #   source: src
            #   target: ${INSTALL_ROOT}/src
            - type: bind
              source: tests
              target: ${INSTALL_ROOT}/tests
            #   read_only: true
        # deploy:
        #   resources:
        #     reservations:
        #       devices:
        #         - driver: nvidia
        #           count: 1
        #           capabilities: [gpu]

        devices:
            - /dev/kfd
            - /dev/dri
        group_add:
            - video
        ipc: host
        cap_add:
            - SYS_PTRACE
        security_opt:
            - seccomp=unconfined

networks:
  llama-network:
    name: llama_backend_network


